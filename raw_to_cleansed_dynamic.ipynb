{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa2bffc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reading: D:\\Ravi_Data_Engineer\\02_Target\\01_raw\\raw_retail_products.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K.PRAVEEN\\AppData\\Local\\Temp\\ipykernel_23764\\632172567.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce',dayfirst=True)  # Convert to datetime, coerce errors to NaT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: raw_retail_products.csv - 500 rows, 6 columns\n",
      "Saved cleaned data to: D:\\Ravi_Data_Engineer\\02_Target\\02_cleansed\\cleansed_retail_products.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re #regex \\. - dot, \\d - digit, \\D -non digit, \\w - alphanumeric, \\W - non alphanumeric\n",
    "\n",
    "src_dir = r'D:\\Ravi_Data_Engineer\\02_Target\\01_raw'\n",
    "tgt_dir = r'D:\\Ravi_Data_Engineer\\02_Target\\02_cleansed'\n",
    "os.makedirs(tgt_dir, exist_ok=True)\n",
    "\n",
    "def clean_datefields(df, output_format='%Y-%m-%d'):\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col.lower():\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce',dayfirst=True)  # Convert to datetime, coerce errors to NaT       \n",
    "                df[col] = df[col].dt.strftime(output_format) #Normalize to desired string format (e.g., YYYY-MM-DD)\n",
    "                \n",
    "            except Exception:\n",
    "                pass \n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_products(df,group_col='Category'):\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df.groupby(group_col)[col].transform(lambda x: x.fillna(x.mean()))  # fill NaN with mean of the column group by category\n",
    "        df[col] = df[col].apply(lambda x: round(x, 2))\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_transactions(df):\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0)  # fill NaN with mean of the column group by transaction type\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].apply(lambda x: round(x, 2))  # round numeric values to 2 decimal places\n",
    "\n",
    "    return df\n",
    "\n",
    "keyword = input(\"Enter the keyword to search in file names:\").lower()\n",
    "\n",
    "files_list_tgt = [f for f in os.listdir(tgt_dir) if keyword in f.lower()]\n",
    "\n",
    "if files_list_tgt:\n",
    "    os.remove(os.path.join(tgt_dir, files_list_tgt[0])) # remove the file if it exists in target directory\n",
    "    print(f\"File {os.path.join(tgt_dir, files_list_tgt[0])} deleted from {tgt_dir}.\")\n",
    "\n",
    "files_list_src = [f for f in os.listdir(src_dir) if keyword in f.lower()]\n",
    "\n",
    "if not files_list_src:\n",
    "    print(f\"No files found containing the keyword '{keyword}' in {src_dir}.\")\n",
    "\n",
    "cleaned_dfs = []\n",
    "\n",
    "for file in files_list_src:\n",
    "    file_path = os.path.join(src_dir, file)\n",
    "    print(f\"\\n Reading: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path) # read csv file\n",
    "\n",
    "        df.columns = df.columns.str.strip() # remove leading and trailing spaces from column names\n",
    "\n",
    "        df.columns = df.columns.str.replace(r'\\.\\d+$', '', regex=True) # replace the last occurrence of a dot followed by digits in column names\n",
    "        df = df.loc[:,~df.columns.duplicated()] # remove duplicate columns\n",
    "\n",
    "        df = df.dropna(how='all') # remove rows where all elements are NaN\n",
    "\n",
    "        string_cols = df.select_dtypes(include='object').columns # checkign the columns with string data type\n",
    "        df[string_cols] = df[string_cols].fillna('Unknown') # replacing the nulls with Unknown\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        df[numeric_cols] = df[numeric_cols].apply(lambda x: round(x, 2)) # rounding numeric values to 2 decimal places\n",
    "\n",
    "        df = df.map(lambda x: x.strip() if isinstance(x, str) else x) # strip leading and trailing spaces from string values in dataframe\n",
    "        df = df.map(lambda x: re.sub(r'[^\\w\\s]', '', str(x)) if isinstance(x, str) else x) # removing special chars from strings\n",
    "\n",
    "        df = df.drop_duplicates() # drop duplicates\n",
    "\n",
    "        #df['Phone'] = df['Phone'].apply(lambda x: re.sub(r'\\D', '', str(x)) if pd.notnull(x) and len(re.sub(r'\\D', '', str(x))) == 10 else '1234567890')\n",
    "        #using lambda, regex to replace find the Phone field and replace per the needed format\n",
    "\n",
    "        df = clean_datefields(df)\n",
    "\n",
    "        if keyword == 'products':\n",
    "            df = clean_products(df) # assuming clean_products is a function defined elsewhere to clean product related data\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if keyword == 'transactions':\n",
    "            df = clean_transactions(df) # assuming clean_transactions is a function defined elsewhere to clean transaction related data\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        cleaned_dfs.append((file, df)) # appended to the cleaned_dfs list\n",
    "        print(f\"Cleaned: {file} - {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "for files in cleaned_dfs:\n",
    "    file_name, df = files\n",
    "    src_file = os.path.join(src_dir,file_name)\n",
    "    orig_name = os.path.splitext(file_name)[0]\n",
    "    ext = os.path.splitext(file_name)[1]\n",
    "    fn = orig_name.replace('raw_', f'cleansed_')\n",
    "    new_name = f\"{fn}{ext}\" # created a new name for the files with prefix as cleansed_\n",
    "    tgt_file = os.path.join(tgt_dir,new_name)\n",
    "      \n",
    "    try:\n",
    "        df.to_csv(tgt_file, index=False)\n",
    "        print(f\"Saved cleaned data to: {tgt_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save {file_name}: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
